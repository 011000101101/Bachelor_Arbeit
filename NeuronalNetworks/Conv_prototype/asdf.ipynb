{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "cross_count = [1.0, 1.0, 1.0, 1.0828, 1.1536, 1.2206, 1.2823, 1.3385, 1.3991, 1.4493, 1.4974, 1.5455, 1.5937, 1.6418,\n",
    "               1.6899, 1.7304, 1.7709, 1.8114, 1.8519, 1.8924, 1.9288, 1.9652, 2.0015, 2.0379, 2.0743, 2.1061, 2.1379,\n",
    "               2.1698, 2.2016, 2.2334, 2.2646, 2.2958, 2.3271, 2.3583, 2.3895, 2.4187, 2.4479, 2.4772, 2.5064, 2.5356,\n",
    "               2.5610, 2.5864, 2.6117, 2.6371, 2.6625, 2.6887, 2.7148, 2.7410, 2.7671, 2.7933]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def get_corrected_bounding_box_cost(bb_cost, number_of_terminals):\n",
    "    \"this computes the crossing value for the net and applies it to the bounding box cost to correct cost of large nets, code taken from VTR placer\"\n",
    "    if number_of_terminals > 50 & number_of_terminals < 85:\n",
    "        crossing = 2.7933 + 0.02616 * (number_of_terminals - 50)\n",
    "    else:\n",
    "        if number_of_terminals >= 85:\n",
    "            crossing = 2.7933 + 0.011 * number_of_terminals - 0.0000018 * number_of_terminals * number_of_terminals\n",
    "        else:\n",
    "            crossing = cross_count[number_of_terminals - 1]\n",
    "\n",
    "    return bb_cost * crossing\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "epochs = 20\n",
    "loss_function = 'mean_squared_error'\n",
    "input_file_names = [\"out.txt\"]\n",
    "optimizer_choice = 'adam'\n",
    "np_random_seed = 8002\n",
    "validation_plotting_point_count = 30\n",
    "\n",
    "# repeatable test runs\n",
    "np.random.seed(np_random_seed)\n",
    "\n",
    "# read training and test data from file and format it...\n",
    "print(\"started\")\n",
    "input_data_set_list = []\n",
    "state = 0\n",
    "current_data_set = []\n",
    "\n",
    "# TODO change if the network architecture changes\n",
    "network_architecture = \"Conv(32,(3,3))-Conv(32,(3,3))-Conv(32,(3,3))-Conv(64,(3,3))-Flatten()-Dense(32,relu)-Dense(1)\"\n",
    "plot_basepath = \"plots/\" + network_architecture + \"/\"\n",
    "data_limit_flag = True\n",
    "data_limit = 250000\n",
    "\n",
    "if not os.path.isdir(plot_basepath):\n",
    "    os.mkdir(plot_basepath)\n",
    "\n",
    "for filename in input_file_names:\n",
    "    input_file = open(filename, \"r\")\n",
    "    lines = input_file.read().splitlines()\n",
    "\n",
    "    for line_number in range(len(lines)):\n",
    "        if line_number % 50000 == 0:\n",
    "            gc.collect()\n",
    "        line = lines[line_number]\n",
    "        if line[0] != '%':\n",
    "            if state == 0:\n",
    "                bb_size = line.split(',')\n",
    "                current_data_set.append(max(int(bb_size[0]), int(bb_size[1])))\n",
    "                current_data_set.append(int(bb_size[0]) + int(bb_size[1]))\n",
    "                state = 1\n",
    "            elif state == 1:\n",
    "                list_of_coord_pairs = line.split(';')\n",
    "                coord_pair_list = []\n",
    "                for coord_pair in list_of_coord_pairs:\n",
    "                    x_y_coords = coord_pair.split(',')\n",
    "                    coord_pair_list.append([int(x_y_coords[0]),\n",
    "                                            int(x_y_coords[1])])\n",
    "                current_data_set.append(coord_pair_list)\n",
    "                current_data_set[1] = get_corrected_bounding_box_cost(current_data_set[1], len(coord_pair_list)) / current_data_set[0]\n",
    "                state = 2\n",
    "            else:\n",
    "                current_data_set.append(int(line))\n",
    "                if current_data_set[0] < 20:\n",
    "                    input_data_set_list.append(current_data_set)\n",
    "                current_data_set = []\n",
    "                state = 0\n",
    "\n",
    "    if data_limit_flag & len(input_data_set_list) >= data_limit:\n",
    "        break\n",
    "\n",
    "    input_file.close()\n",
    "    gc.collect()\n",
    "\n",
    "# data = np.array(input_coord_lists, dtype= float)\n",
    "# target = np.array(output_costs, dtype= float)\n",
    "\n",
    "max_grid_size = max(data[0] for data in input_data_set_list) + 1\n",
    "print(\"grid size: \", max_grid_size, \"x\", max_grid_size)\n",
    "\n",
    "# print(\"input data array:\")\n",
    "# print(input_data_set_list)\n",
    "\n",
    "print(\"file read,\", len(input_data_set_list), \"datasets loaded.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# shuffle true by default, default random number generator is np.random, seeded above\n",
    "data_train, data_test = train_test_split(input_data_set_list, test_size=(10*int(math.sqrt(len(input_data_set_list)))))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for dataset in data_train:\n",
    "    mapped_data = np.zeros((max_grid_size, max_grid_size), int)\n",
    "    for coordinates in dataset[2]:\n",
    "        mapped_data[coordinates[0]][coordinates[1]] = 1\n",
    "    X.append(mapped_data)\n",
    "    y.append(dataset[3])\n",
    "\n",
    "print(np.asarray(X).shape)\n",
    "print(np.asarray(X).shape[1:])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model definition\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), input_shape=(max_grid_size, max_grid_size, 1), activation=\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optimizer_choice, metrics=[loss_function])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Log all variables for Tensorboard\n",
    "\"\"\"for some_variable in tf.trainable_variables():\n",
    "    tf.summary.histogram(some_variable.name.replace(\":\",\"_\"), some_variable)\n",
    "merged_summary = tf.summary.merge_all()\"\"\"\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(network_architecture + \"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir, histogram_freq=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(np.asarray(X).reshape(len(X), max_grid_size, max_grid_size, 1), np.asarray(y), epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[tensorboard_cb])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}